import logging
from typing import Optional, Dict, Any
from app.config import settings, CLASSIFICATION_PROMPT, build_extraction_prompt
from app.models.prompt_schemas import SUPPORTED_CATEGORIES

logger = logging.getLogger(__name__)

class LLMService:
    """LLMæœåŠ¡ç±» - ç»Ÿä¸€ç®¡ç†ä¸åŒAIæ¨¡å‹"""
    
    def __init__(self):
        self.categories = ["å‘ç¥¨", "ç§Ÿèµåè®®", "å˜æ›´/è§£é™¤åè®®", "è´¦å•", "é“¶è¡Œå›å•"]
        
        # ä»é…ç½®è·å–é»˜è®¤æ¨¡å‹ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨qwen
        from app.config import settings
        self.default_model = getattr(settings, 'llm_default_model', 'qwen')
        logger.info(f"LLM service initialized with default model: {self.default_model}")
    
    def classify_file_sync(self, file_content: bytes, file_type: str, filename: str, model_type: Optional[str] = None) -> Dict[str, Any]:
        """åˆ†ç±»æ–‡ä»¶ - åŒæ­¥ç‰ˆæœ¬"""
        try:
            # ä½¿ç”¨é»˜è®¤æ¨¡å‹å¦‚æœæœªæŒ‡å®š
            if not model_type:
                model_type = self.default_model
            
            # è®°å½•ä½¿ç”¨çš„æ¨¡å‹
            logger.info(f"ğŸ¤– Using {model_type.upper()} model for file classification: {filename}")
            
            # ä»é…ç½®ä¸­è·å–åˆ†ç±»æç¤ºè¯
            prompt = CLASSIFICATION_PROMPT.format(filename=filename, file_type=file_type)
            
            # è®°å½•å‘é€ç»™AIæ¨¡å‹çš„åˆ†ç±»æç¤ºè¯ï¼ˆç”¨äºè°ƒè¯•ï¼‰
            logger.info(f"=== {model_type.upper()} CLASSIFICATION PROMPT ===")
            logger.info(f"Filename: {filename}")
            logger.info(f"File type: {file_type}")
            logger.info(f"Model: {model_type}")
            logger.info(f"Prompt length: {len(prompt)} characters")
            logger.info(f"Full prompt:\n{prompt}")
            logger.info(f"=== END {model_type.upper()} CLASSIFICATION PROMPT ===")
            
            # æ ¹æ®æ¨¡å‹ç±»å‹è°ƒç”¨ç›¸åº”çš„æœåŠ¡
            if model_type.lower() == "gemini":
                from app.services.gemini_service import gemini_service
                response = gemini_service._classify_file_sync(file_content, file_type, filename, prompt)
            elif model_type.lower() == "qwen":
                from app.services.qwen_service import qwen_service
                response = qwen_service._classify_file_sync(file_content, file_type, filename, prompt)
            else:
                raise ValueError(f"Unsupported model type: {model_type}")
            
            # è®°å½•AIæ¨¡å‹çš„åŸå§‹å“åº”
            logger.info(f"{model_type} raw response for classification from {filename}: {response.get('text', 'No text response')}")
            
            # è§£æå“åº”
            result = self._parse_classification_response(response, model_type)
            
            logger.info(f"File classified as: {result.get('category', 'Unknown')} with confidence: {result.get('confidence', 0.0)}")
            
            return result
            
        except Exception as e:
            logger.error(f"File classification failed for file {filename}: {e}")
            return {
                "category": "æœªè¯†åˆ«",
                "confidence": 0.0,
                "reason": f"åˆ†ç±»å¤±è´¥: {str(e)}",
                "key_info": "æ— æ³•å¤„ç†æ­¤æ–‡ä»¶"
            }
    
    def extract_fields_sync(self, file_content: bytes, file_type: str, filename: str, category: str, model_type: Optional[str] = None) -> Dict[str, Any]:
        """æå–å­—æ®µ - åŒæ­¥ç‰ˆæœ¬"""
        try:
            # ä½¿ç”¨é»˜è®¤æ¨¡å‹å¦‚æœæœªæŒ‡å®š
            if not model_type:
                model_type = self.default_model
            
            # è®°å½•ä½¿ç”¨çš„æ¨¡å‹
            logger.info(f"ğŸ¤– Using {model_type.upper()} model for field extraction: {filename} (category: {category})")
            
            # éªŒè¯åˆ†ç±»å‚æ•°
            if not category or category.strip() == "":
                raise ValueError("Category is required for field extraction")
            
            # éªŒè¯åˆ†ç±»æ˜¯å¦åœ¨æ”¯æŒçš„ç±»åˆ«ä¸­
            if category not in SUPPORTED_CATEGORIES:
                raise ValueError(f"Unsupported category '{category}'. Supported categories: {SUPPORTED_CATEGORIES}")
            
            # ä½¿ç”¨æä¾›çš„åˆ†ç±»ä¿¡æ¯
            classification_confidence = 1.0  # å‡è®¾æä¾›çš„åˆ†ç±»æ˜¯å‡†ç¡®çš„
            classification_reason = "ä½¿ç”¨æä¾›çš„åˆ†ç±»"
            
            if category == "æœªè¯†åˆ«":
                return {
                    "category": "æœªè¯†åˆ«",
                    "classification_confidence": classification_confidence,
                    "classification_reason": classification_reason,
                    "extraction_data": {},
                    "missing_fields": [],
                    "extraction_confidence": 0.0,
                    "notes": "æ–‡æ¡£ç±»å‹æœªè¯†åˆ«ï¼Œæ— æ³•è¿›è¡Œå­—æ®µæå–"
                }
            
            # æ„å»ºæå–æç¤ºè¯
            prompt = build_extraction_prompt(category)
            
            # è®°å½•å‘é€ç»™AIæ¨¡å‹çš„å®Œæ•´æç¤ºè¯ï¼ˆç”¨äºè°ƒè¯•ï¼‰
            logger.info(f"=== {model_type.upper()} FIELD EXTRACTION PROMPT FOR {category.upper()} ===")
            logger.info(f"Filename: {filename}")
            logger.info(f"File type: {file_type}")
            logger.info(f"Category: {category}")
            logger.info(f"Model: {model_type}")
            logger.info(f"Prompt length: {len(prompt)} characters")
            logger.info(f"Full prompt:\n{prompt}")
            logger.info(f"=== END {model_type.upper()} FIELD EXTRACTION PROMPT ===")
            
            # æ ¹æ®æ¨¡å‹ç±»å‹è°ƒç”¨ç›¸åº”çš„æœåŠ¡
            if model_type.lower() == "gemini":
                from app.services.gemini_service import gemini_service
                response = gemini_service._extract_fields_sync(file_content, file_type, filename, prompt)
            elif model_type.lower() == "qwen":
                from app.services.qwen_service import qwen_service
                response = qwen_service._extract_fields_sync(file_content, file_type, filename, prompt)
            else:
                raise ValueError(f"Unsupported model type: {model_type}")
            
            # è®°å½•AIæ¨¡å‹çš„åŸå§‹å“åº”
            logger.info(f"{model_type} raw response for field extraction from {filename}: {response.get('text', 'No text response')}")
            
            # è§£æå“åº”
            result = self._parse_extraction_response(response, model_type)
            
            # ç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„åˆ†ç±»ä¿¡æ¯
            result["category"] = category
            result["classification_confidence"] = classification_confidence
            result["classification_reason"] = classification_reason
            
            logger.info(f"Fields extracted from {filename}, category: {category}")
            
            return result
            
        except Exception as e:
            logger.error(f"Field extraction failed for file {filename}: {e}")
            return {
                "category": "æœªè¯†åˆ«",
                "classification_confidence": 0.0,
                "classification_reason": f"å­—æ®µæå–å¤±è´¥: {str(e)}",
                "extraction_data": {},
                "missing_fields": [],
                "extraction_confidence": 0.0,
                "notes": f"æå–å¤±è´¥: {str(e)}"
            }
    
    def _parse_classification_response(self, response: Dict[str, Any], model_type: str) -> Dict[str, Any]:
        """è§£æåˆ†ç±»å“åº”"""
        try:
            if model_type.lower() == "gemini":
                # Geminiè¿”å›çš„æ˜¯textå­—æ®µ
                response_text = response.get("text", "")
            elif model_type.lower() == "qwen":
                # Qwenè¿”å›çš„æ˜¯textå­—æ®µ
                response_text = response.get("text", "")
            else:
                response_text = str(response)
            
            # å°è¯•è§£æJSONå“åº”
            import json
            try:
                # æå–JSONéƒ¨åˆ†ï¼ˆå¦‚æœå“åº”åŒ…å«å…¶ä»–æ–‡æœ¬ï¼‰
                json_start = response_text.find('{')
                json_end = response_text.rfind('}') + 1
                if json_start != -1 and json_end > json_start:
                    json_text = response_text[json_start:json_end]
                    parsed = json.loads(json_text)
                else:
                    parsed = json.loads(response_text)
                
                return {
                    "category": parsed.get("category", "æœªè¯†åˆ«"),
                    "confidence": float(parsed.get("confidence", 0.0)),
                    "reason": parsed.get("reason", "æ— ç†ç”±"),
                    "key_info": parsed.get("key_info", "æ— å…³é”®ä¿¡æ¯")
                }
                
            except json.JSONDecodeError:
                logger.warning(f"Failed to parse JSON response from {model_type}: {response_text}")
                return {
                    "category": "æœªè¯†åˆ«",
                    "confidence": 0.0,
                    "reason": f"å“åº”æ ¼å¼é”™è¯¯: {response_text[:100]}",
                    "key_info": "æ— æ³•è§£æå“åº”"
                }
                
        except Exception as e:
            logger.error(f"Error parsing classification response from {model_type}: {e}")
            return {
                "category": "æœªè¯†åˆ«",
                "confidence": 0.0,
                "reason": f"è§£æå¤±è´¥: {str(e)}",
                "key_info": "è§£æé”™è¯¯"
            }
    
    def _parse_extraction_response(self, response: Dict[str, Any], model_type: str) -> Dict[str, Any]:
        """è§£æå­—æ®µæå–å“åº”"""
        try:
            if model_type.lower() == "gemini":
                # Geminiè¿”å›çš„æ˜¯textå­—æ®µ
                response_text = response.get("text", "")
            elif model_type.lower() == "qwen":
                # Qwenè¿”å›çš„æ˜¯textå­—æ®µ
                response_text = response.get("text", "")
            else:
                response_text = str(response)
            
            # å°è¯•è§£æJSONå“åº”
            import json
            try:
                # æå–JSONéƒ¨åˆ†ï¼ˆå¦‚æœå“åº”åŒ…å«å…¶ä»–æ–‡æœ¬ï¼‰
                json_start = response_text.find('{')
                json_end = response_text.rfind('}') + 1
                if json_start != -1 and json_end > json_start:
                    json_text = response_text[json_start:json_end]
                    parsed = json.loads(json_text)
                else:
                    parsed = json.loads(response_text)
                
                return {
                    "category": parsed.get("category", "æœªè¯†åˆ«"),
                    "classification_confidence": float(parsed.get("classification_confidence", 1.0)),
                    "classification_reason": parsed.get("classification_reason", "ä½¿ç”¨æä¾›çš„åˆ†ç±»"),
                    "extraction_data": parsed.get("extraction_data", {}),
                    "missing_fields": parsed.get("missing_fields", []),
                    "extraction_confidence": float(parsed.get("extraction_confidence", 0.0)),
                    "notes": parsed.get("notes", "å­—æ®µæå–å®Œæˆ")
                }
                
            except json.JSONDecodeError:
                logger.warning(f"Failed to parse JSON response from {model_type}: {response_text}")
                return {
                    "category": "æœªè¯†åˆ«",
                    "classification_confidence": 0.0,
                    "classification_reason": f"å“åº”æ ¼å¼é”™è¯¯: {response_text[:100]}",
                    "extraction_data": {},
                    "missing_fields": [],
                    "extraction_confidence": 0.0,
                    "notes": f"è§£æå¤±è´¥: {response_text[:100]}"
                }
                
        except Exception as e:
            logger.error(f"Error parsing extraction response from {model_type}: {e}")
            return {
                "category": "æœªè¯†åˆ«",
                "classification_confidence": 0.0,
                "classification_reason": f"è§£æå¤±è´¥: {str(e)}",
                "extraction_data": {},
                "missing_fields": [],
                "extraction_confidence": 0.0,
                "notes": f"è§£æå¤±è´¥: {str(e)}"
            }

# å…¨å±€LLMæœåŠ¡å®ä¾‹
llm_service = LLMService()
